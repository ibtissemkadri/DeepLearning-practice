{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand written digits recognition with Convolutional Neural Network (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to build a Convolutional Neural Network model to recognize hand written digits using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils, plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train_orig, y_train_orig), (X_test_orig, y_test_orig) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_orig shape: (60000, 28, 28)\n",
      "y_train_orig shape: (60000,)\n",
      "X_test_orig shape: (10000, 28, 28)\n",
      "y_test_orig shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train_orig shape: '+str(X_train_orig.shape))\n",
    "print('y_train_orig shape: '+str(y_train_orig.shape))\n",
    "print('X_test_orig shape: '+str(X_test_orig.shape))\n",
    "print('y_test_orig shape: '+str(y_test_orig.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired shape for our input layer is (m, 28, 28, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "X_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig.reshape(-1,28,28,1)\n",
    "X_test = X_test_orig.reshape(-1,28,28,1)\n",
    "print('X_train shape: '+str(X_train.shape))\n",
    "print('X_test shape: '+str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to Convert 1-dimensional class arrays to 10-dimensional class matrices: **one hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (60000, 10)\n",
      "y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train_orig, 10)\n",
    "y_test = np_utils.to_categorical(y_test_orig, 10)\n",
    "print('y_train shape: '+str(y_train.shape))\n",
    "print('y_test shape: '+str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build a model to classify the images in the MNIST dataset using the following CNN architecture:\n",
    "\n",
    "1. Convolutional Layer #1: Applies 32 5x5 filters (extracting 5x5-pixel subregions) with \"same\" padding and applying Batch Normalization and ReLU activation function\n",
    "2. Pooling Layer #1: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
    "3. Convolutional Layer #2: Applies 64 5x5 filters with \"same\" padding and applying Batch Normalization and ReLU activation function\n",
    "4. Pooling Layer #2: Again, performs max pooling with a 2x2 filter and stride of 2\n",
    "5. Dense Layer #1: 128 neurons, with dropout regularization rate of 0.5 (probability of 0.4 that any given element will be dropped during training)\n",
    "6. Dense Layer #2 (Logits Layer): 10 neurons, one for each digit target class (0â€“9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DigitRecognition(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(32, (5,5), strides=(1,1), name='Conv0')(X_input)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D((2,2), name='max_pool0')(X)\n",
    "    \n",
    "    X = Conv2D(64, (5,5), strides=(1,1), name='Conv1')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D((2,2), name='max_pool1') (X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(128, activation='relu', name='FC0')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(10, activation='softmax', name='FC1')(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=X, name='DigitRecognitionModel')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DigitRecognitionModel = DigitRecognition((28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DigitRecognitionModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 416s 7ms/step - loss: 0.2013 - acc: 0.9396\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 404s 7ms/step - loss: 0.0928 - acc: 0.9727\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 413s 7ms/step - loss: 0.0729 - acc: 0.9796\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 437s 7ms/step - loss: 0.0569 - acc: 0.9836\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 443s 7ms/step - loss: 0.0473 - acc: 0.9860\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 434s 7ms/step - loss: 0.0412 - acc: 0.9878\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 430s 7ms/step - loss: 0.0366 - acc: 0.9891\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 451s 8ms/step - loss: 0.0307 - acc: 0.9908\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 451s 8ms/step - loss: 0.0279 - acc: 0.9914\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 433s 7ms/step - loss: 0.0251 - acc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21d00cf240>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DigitRecognitionModel.fit(x=X_train, y=y_train, batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 25s 3ms/step\n",
      "loss=0.022998055769\n",
      "test accuracy=0.9925\n"
     ]
    }
   ],
   "source": [
    "preds = DigitRecognitionModel.evaluate(x=X_test, y=y_test)\n",
    "print(\"loss=\"+str(preds[0]))\n",
    "print(\"test accuracy=\"+str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
